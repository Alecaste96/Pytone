{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il ruolo dell'attaccante è fondamentale nel gioco del calcio. E' compito suo infatti fare gol ma non solo, è anche un'ottima chiave di gioco per la creazione degli spazi utili per i compagni di squadra o anche per difendere il pallone in una zona di campo lontana dalla propria area e permettere così al team di rifiatare e alzare il baricentro. In questa sezione ci occupiamo della parte 'demografica' degli attaccanti di Serie A. Andremo ad analizzare come sono distribuite le età, le nazionalità ed i minuti giocati, per gli attaccanti. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import tensorflow as tf\n",
    "import funzioni\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.widgets import Slider\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Elenco dei file da leggere\n",
    "files = ['attaccanti_23.xlsx', 'attaccanti_22.xlsx', 'attaccanti_21.xlsx', 'attaccanti_20.xlsx', 'attaccanti_19.xlsx']\n",
    "\n",
    "# Dizionario per mappare i file agli anni\n",
    "year_mapping= {'attaccanti_23.xlsx': 2023,'attaccanti_22.xlsx': 2022,'attaccanti_21.xlsx': 2021,'attaccanti_20.xlsx': 2020,\n",
    "                'attaccanti_19.xlsx': 2019}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cella utile inserita in caso ci fossero aggiornamenti delle funzioni da importare\n",
    "\n",
    "import importlib\n",
    "importlib.reload(funzioni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisco fasce di età e etichette\n",
    "bins = [15, 20, 25, 30, 35, 40]\n",
    "labels = ['15-20', '21-25', '26-30', '31-35', '36-40']\n",
    "\n",
    "# Dizionario per conservare i conteggi annuali per ciascuna fascia d'età\n",
    "fasce_eta_conti = {label: [] for label in labels}\n",
    "medie_totali_annuali = []\n",
    "deviazioni_annuali = []\n",
    "\n",
    "# Ciclo sui file per calcolare la numerosità per ciascuna fascia, la media totale e la deviazione standard\n",
    "for file in files:\n",
    "    data = pd.read_excel(file)\n",
    "    eta = data['Age']\n",
    "\n",
    "    # Categorizzazione delle età nelle fasce specificate\n",
    "    eta_bins = pd.cut(eta, bins=bins, labels=labels, right=True, include_lowest=True)\n",
    "\n",
    "    # Conteggio il numero di giocatori per ciascuna fascia di età\n",
    "    for label in labels:\n",
    "        conteggio_eta_fascia = (eta_bins == label).sum()\n",
    "        fasce_eta_conti[label].append(conteggio_eta_fascia)\n",
    "\n",
    "    # Calcolo media e deviazione standard\n",
    "    medie_totali_annuali.append(eta.mean())\n",
    "    deviazioni_annuali.append(eta.std(ddof=1))\n",
    "\n",
    "anni = ['2019', '2020', '2021', '2022', '2023']  \n",
    "\n",
    "# Creazione del grafico a barre\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "mini_bar_width = 0.8 / len(anni) \n",
    "x_pos = np.arange(len(labels))\n",
    "\n",
    "for i, anno in enumerate(anni):\n",
    "    conti_annuali = [fasce_eta_conti[label][i] for label in labels]\n",
    "    offset = (i - (len(anni) - 1) / 2) * mini_bar_width\n",
    "    ax.bar(x_pos + offset, conti_annuali, mini_bar_width, label=anno)\n",
    "\n",
    "ax.set_xlabel('Fascia di Età')\n",
    "ax.set_ylabel('Numero di Giocatori')\n",
    "ax.set_title('Numero di Attaccanti per Fascia di Età e Anno')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend(title='Anno')\n",
    "\n",
    "ax.set_yticks(np.arange(0, max(max(fasce_eta_conti.values())) + 5, 5))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 2° Grafico\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(anni, medie_totali_annuali, marker='o', color='k', label='Media Totale')\n",
    "\n",
    "# Barre di errore\n",
    "ax.errorbar(anni, medie_totali_annuali, yerr=deviazioni_annuali, fmt='o', color='k', label='Deviazione Standard')\n",
    "\n",
    "ax.set_xlabel('Anno')\n",
    "ax.set_ylabel('Media Età')\n",
    "ax.set_title(\"Andamento della Media Totale dell'Età dal 2019 al 2023\")\n",
    "\n",
    "ax.set_ylim(15, 40)\n",
    "ax.set_yticks(np.arange(15, 40, 1))\n",
    "\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dopo aver importato i file necessari andiamo ad analizzare come sono variate le età nei 5 anni analizzati, visualizziamo il tutto con una serie di istogrammi riferiti alle varie fasce di età. Si nota come il valore compreso tra i 21 e i 25 anni sia il più diffuso nel ruolo, seguito da 26-30 e 15-20. Da tenere in considerazione inoltre l'aumento progressivo dell'utilizzo sempre maggiore di giovanissimi, i quali vengono fatti esordire prematuramente. Dal 2020 al 2023 infatti il dato è in costante aumento, e ciò si conferma anche con i discorsi molto ripresi nel corso di questi anni, dove la maggior parte delle squadre di Serie A provano a ringiovanire l'organico e a ricercare sempre più giovani talenti da valorizzare e rivendere ad un prezzo maggiore.\n",
    "Il secondo grafico, riferito alla media di età nel corso degli anni, si nota una error bar notevole, che dipende proprio dalle grandi differenze di età che si possono trovare nel parco attaccanti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passiamo ora all'analisi delle nazionalità. Vediamo quali sono le nazionalità più presenti in Serie A utilizzando il concept precedente, in modo da avere un confronto diretto anno per anno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteggio delle nazionalità per ciascun anno\n",
    "all_counts = {}\n",
    "for file in files:\n",
    "    data = pd.read_excel(file)\n",
    "    year = year_mapping[file]\n",
    "    nazionalita_counts = data['Nation'].value_counts()\n",
    "    all_counts[year] = nazionalita_counts\n",
    "\n",
    "# Unione dei dati in un DataFrame\n",
    "df_counts = pd.DataFrame(all_counts).fillna(0)\n",
    "\n",
    "# Creazione di un grafico a barre\n",
    "fig = go.Figure()\n",
    "\n",
    "for year in df_counts.columns:\n",
    "    fig.add_trace(go.Bar( x=df_counts.index, y=df_counts[year], name=str(year)))\n",
    "\n",
    "# Barra di scorrimento così da favorire la visualizzazione\n",
    "fig.update_layout(title=\"Distribuzione delle Nazionalità degli attaccanti per gli anni 2019-2023\",\n",
    "                  xaxis=dict(title=\"Nazionalità\", tickangle=45, automargin=True,rangeslider=dict(visible=True) ),   \n",
    "                  yaxis=dict( title=\"Numero di calciatori\", tick0=0, dtick=5),barmode='group', width=2000)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come da aspettativa, la nazionalità italiana risulta nettamente la più diffusa, questo appunto per via del campionato preso in esame. Risultano sorprendenti invece i dati relativi ad Argentina, Brasile e Costa d'Avorio, le quali hanno un indice molto alto e distaccato rispetto alle altre nazionalità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistiche_minuti_per_anno = {}\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_excel(file)\n",
    "    valori = data['MP']  \n",
    "    \n",
    "    # Filtraggio i dati per includere solo i calciatori con più di 20 minuti giocati\n",
    "    valori_filtrati = valori[valori > 20]\n",
    "\n",
    "    media_valori_filtrati = valori_filtrati.mean()\n",
    "    deviazione_standard = valori_filtrati.std()\n",
    "    \n",
    "    # Aggiunta dei valori al dizionario\n",
    "    year = year_mapping[file]\n",
    "    statistiche_minuti_per_anno[year] = (media_valori_filtrati, deviazione_standard)\n",
    "\n",
    "# Creazione di un DataFrame per le statistiche dei minuti giocati per anno\n",
    "df_statistiche = pd.DataFrame( [(year, stat[0], stat[1]) for year, stat in statistiche_minuti_per_anno.items()], \n",
    "                              columns=['Anno', 'Media Minuti', 'Deviazione Standard'])\n",
    "\n",
    "# Ordinamento del DataFrame per anno\n",
    "df_statistiche = df_statistiche.sort_values('Anno')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Errorbar\n",
    "\n",
    "plt.errorbar( df_statistiche['Anno'], df_statistiche['Media Minuti'], yerr=df_statistiche['Deviazione Standard'], fmt='o',\n",
    "              ecolor='k', capsize=5, color='k', label='Media Minuti Giocati')\n",
    "plt.plot(df_statistiche['Anno'], df_statistiche['Media Minuti'], color='k', linestyle='-', linewidth=2, label='Linea di Tendenza')\n",
    "\n",
    "# Personalizzazione i tick dell'asse x per mostrare solo gli anni\n",
    "plt.xticks(df_statistiche['Anno'], fontsize=12)\n",
    "\n",
    "plt.xlabel('Anno', fontsize=14)\n",
    "plt.ylabel('Media Minuti Giocati', fontsize=14)\n",
    "plt.title('Media dei Minuti Giocati dai Calciatori per Anno con Barre di Errore', fontsize=16)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questi grafici vediamo la distribuzione dei minuti giocati diviso 90 dagli attaccanti. In altre parole calcoliamo quante partite complete vengono giocate dagli attaccanti. Abbiamo messo un bound inferiore di 20 minuti giocati per evitare che i dati vengano sfalsati da giocatori con pochi minuti giocati. Vediamo che la distribuzione e la media rimane più o meno la stessa nel corso degli anni. La media addirittura oscilla fra 29.42 e 29.98. Dal grafico si ottiene anche un insolito calo dei minuti giocati nel 2022, probabilmente dovuto dalla presenza di numerose squadre con un assetto ad attaccanti a 2 e non a 3 come negli anni precedenti. Considerando la possibilità di 5 sostituzioni per partita per ogni squadra, si giustificano gli scarti del grafico dal fatto che l'impiego dei giocatori subentrati dalla panchina, i quali hanno un minutaggio per partita considerevolmente minore rispetto ai giocatori titolari."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiungiamo una cella di codice che stampa gli istogrammi di tutte le statistiche di tutti 5 gli anni. In modo da poterli \n",
    "analizzare singolarmente in seguito, senza appesantire il codice con tutti i grafici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funzioni import freedman_diaconis_bins\n",
    "for file in files:\n",
    "    data = pd.read_excel(file)\n",
    "\n",
    "    # Selezione solo delle colonne numeriche\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Creazione di istogrammi per ogni colonna numerica\n",
    "    for column in numeric_data.columns:\n",
    "        col_data = numeric_data[column].dropna()  \n",
    "\n",
    "        if col_data.nunique() <= 1:\n",
    "            continue\n",
    "\n",
    "        # Calcolo dei bin\n",
    "        bins = freedman_diaconis_bins(col_data)\n",
    "\n",
    "        # Istogramma\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(col_data, bins=bins, color='k', edgecolor='r', label='Dati')\n",
    "\n",
    "        plt.title(f'Istogramma della colonna: {column}')\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel('Numero di giocatori')\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "        # Calcolo della media e sua stampa a video\n",
    "        #media = col_data.mean()\n",
    "        #print(f\"La media di {column} per l'anno {year_mapping[file]} è: {media:.2f}\")\n",
    "\n",
    "# Le ultime due righe sono state commentate perche altrimenti il codice avrebbe stampato grafico e media di ogni statistica \n",
    "# per tutti i 5 gli anni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo una funzione che, dati in input la statistica e l'anno desiderato, restituisce l'istogramma di quella statistica\n",
    "relativa a quell'anno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con questa funzione possiamo richiamare dei grafici specifici e analizzarli se ci interessa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funzioni import istogramma\n",
    "statistica = 'Gls'\n",
    "anno = 2020\n",
    "istogramma(statistica, anno, year_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELAZIONI\n",
    "\n",
    "INTRODUZIONE\n",
    "\n",
    "Il calcio moderno è diventato molto caro, sopratutto il reparto di attacco. Le società chiedono tantissimi soldi per un giocatore \"solamente\" perchè ha realizzato molti Gol o Assist nella stagione precedente. Non tutte le squadre, però, hanno una disponibilità economica elevata per comprare un attaccante già affermato. La nostra tesi è che esistano delle correlazioni, fra le statistiche sopracitate e le altre di gioco, che una squadra può andare a studiare per stimare il numero di Gol e Assist che può realizzare un attaccante. In questo modo una società non sarà costretta ad affidarsi al numero di Gol ed Assist e potrà comprare giocatori altrettanto validi ad un prezzo minore, risparmiando soldi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA CLEANING\n",
    "\n",
    "Prima di procedere con l'analisi bisogna fare un processo di 'data cleaning' ovvero una pulizia del dataframe, aggiungendo colonne che possono essere utili oppure togliendone altre che non vogliamo prendere in considerazione.\n",
    "\n",
    "Eliminiamo cartellini gialli e rossi collezionati dai giocatori, in quanto rappresentano la disciplina di questi e non le loro capacità balistiche. Dopodiche eliminiamo le colonne relative ai calci piazzati in quanto rigori e punizioni hanno i propri specialisti scelti dall'allenatore, non sarebbe quindi equo considerare una statistica alla quale la maggior parte dei giocatori non prendono neanche parte.\n",
    "\n",
    "Ovviamente scartiamo le celle relative al Nome del giocatore, la Squadra per cui gioca e la sua Nazionalità. Subito dopo togliamo quelle colonne che rappresentano \"operazioni\" fra altre statistiche, come ad esempio somme fra due dati, percentuali o rapporti, in quanto non sono statistiche di gioco (realizzate sul campo dal giocatore) ma create ad hoc per altri tipi di analisi non inerenti al nostro.\n",
    "\n",
    "Queste statistiche non verranno mai considerate in questa parte del progetto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suddivideremo le statistiche del database in 4 categorie e le analizzeremo una ad una.\n",
    "\n",
    "1) STATISTICHE DI IMPIEGO\n",
    "\n",
    "La prima categoria riguarda le statistiche non di campo, quelle relative ad età, minutaggio e partite giocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea 5 matrici colorate in cui ogni quadratino rappresenta l'indice di  correlazione fra le statistiche per annata\n",
    "colonne_da_eliminare = ['Player', 'Nation', 'Pos', 'Squad','G+A', 'G-PK', 'PK',\n",
    "       'PKatt', 'CrdY', 'CrdR', 'xG', 'PrgP', 'PrgR', 'Sh', 'SoT', 'SoT%',\n",
    "       'G/Sh', 'G/SoT', 'Dist', 'FK', 'G-xG', 'Cmp', 'Att', 'Cmp%', 'xA', 'KP',\n",
    "       'PPA', 'CrsPA', 'SCA', 'GCA', 'Tkl', 'TklW', 'Mid 3rd', 'Att 3rd',\n",
    "       'Touches', 'Mid 3rd.1', 'Att 3rd.1', 'Att.1', 'Succ', 'Succ%',\n",
    "       'Carries', 'TotDist', '2CrdY', 'Fld', 'Off', 'Crs', 'Won', 'Lost',\n",
    "       'Won%']\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    data_frame = pd.read_excel(file)\n",
    "\n",
    "    # Uso .drop per rimuovere dal data frame quelle statistiche che non voglio usare in questa analisi\n",
    "    data_frame.drop(columns=colonne_da_eliminare, inplace=True) \n",
    "\n",
    "    corr_matrix = data_frame.corr()  # Calcolo la matrice di correlazione\n",
    "\n",
    "    fig = px.imshow(corr_matrix, title=f\"Matrice di Correlazione - Anno {year_mapping[file]}\", zmin = -1, zmax = 1)\n",
    "    # Ottengo in output il grafico di correlazione\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Inserisco questa riga di codice in modo da poter visualizzare le colonne usate per l'analisi\n",
    "print(f'Le colonne usate per questa analisi sono {list(data_frame.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il codice stampa delle matrici interattive quadrate simmetriche dove ogni cella è colorata in base all'indice di correlazione delle statistiche scritte sulla riga e colonna corrispondente. Ovviamente la diagonale ha tutti i valori uguali ad uno in quanto indica la correlazione di una statistica con se stessa.\n",
    "Diciamo che è interattiva in quanto mettendo il cursore su un quadrato vengono indicate le statistiche e l'indice fra di loro.\n",
    "Sulla destra è riportata una barra che fa da legenda, con la quale si può associare al colore il valore dell'indice, vengono impostati estremi fissi e non variabili durante tutte l'analisi in modo che i colori possano aiutarci in una fase preliminare dell'analisi.\n",
    "\n",
    "L'indice di correlazione è un numero compreso tra -1 e 1 che indica la relazione fra due variabili. Un indice di correlazione positivo indica che all'aumentare di una statistica anche l'altra lo fa. Mentre quello negativo indica che all'aumentare di una l'altra diminuisce. Più questo valore è vicino all'uno, in modulo, più la relazione è forte, più ci si avvicina allo zero più è debole\n",
    "\n",
    "A noi importa analizzare gli indici delle statistiche con Gol ed Assist, quindi guardiamo le ultime due righe (colonne). \n",
    "Con la matrice possiamo farci un'idea preliminare, grazie ai colori, dell'indice di correlazione fra le statistiche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo una funzione che restituisce l'elenco degli indci di correlazione di una statistica con le altre anno per anno\n",
    "\n",
    "def correlazioni_annuali(stat):\n",
    "    for file in files:\n",
    "        data_frame = pd.read_excel(file)  \n",
    "\n",
    "        data_frame.drop(columns=colonne_da_eliminare, inplace=True)\n",
    "\n",
    "        corr_matrix = data_frame.corr()\n",
    "\n",
    "        if stat in corr_matrix.columns:\n",
    "            sorted_corr = corr_matrix[stat].sort_values(ascending=False)\n",
    "\n",
    "            print(f\"Anno {year_mapping[file]}: Le correlazioni per {stat} sono:\\n{sorted_corr}\\n\")\n",
    "        else:\n",
    "            print(f\"La statistica {stat} non è presente nel dataset dell'anno {year_mapping[file]}.\")\n",
    "        \n",
    "# Creo una seconda funzione che mi dice l'indice di correlazione di due statistiche specifiche\n",
    "# ed il cambiamento di questo nel corso delle stagioni\n",
    "\n",
    "def correlazione(stat1,stat2):\n",
    " correlations = []\n",
    "\n",
    " for file in files:\n",
    "    \n",
    "    data_frame = pd.read_excel(file)\n",
    "\n",
    "    data_frame.drop(columns=colonne_da_eliminare, inplace=True)\n",
    "\n",
    "    corr_matrix = data_frame.corr()\n",
    "\n",
    "    # Verifica se entrambe le statistiche esistono nella matrice di correlazione\n",
    "    if stat1 in corr_matrix.columns and stat2 in corr_matrix.columns:\n",
    "        correlation_value = corr_matrix.loc[stat1, stat2]\n",
    "        correlations.append((year_mapping[file], correlation_value))\n",
    "        print(f\"Anno {year_mapping[file]}: Indice {correlation_value}\")\n",
    "    else:\n",
    "        correlations.append((year, None))\n",
    "\n",
    "# Creazione del DataFrame per il grafico\n",
    " if stat1 in corr_matrix.columns and stat2 in corr_matrix.columns:\n",
    "    correlation_df = pd.DataFrame(correlations, columns=['Anno', 'Correlazione'])\n",
    "    \n",
    "    # Crea il grafico dell'andamento della correlazione nel tempo\n",
    "    fig = px.line(correlation_df, x='Anno', y='Correlazione', title=f\"Correlazione tra {stat1} e {stat2}\", markers=True)\n",
    "    fig.update_xaxes(dtick=1)\n",
    "    fig.update_yaxes(range = [-1,1], dtick = 0.10)\n",
    "    fig.show()\n",
    "    print(f\"Il massimo valore dell'indice fra {stat1} e {stat2} è {correlation_df['Correlazione'].max()} il valore minimo è {correlation_df['Correlazione'].min()}\")\n",
    " else:\n",
    "    print(\"Nessun grafico disponibile: non sono state calcolate correlazioni valide. Controlla l'input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci aiutiamo con delle funzioni per plottare l'andamento di questi indici negli anni considerati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data_frame.columns:\n",
    "    if column not in ['Gls','Ast']:\n",
    "     correlazione('Gls',column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo che l'unica coppia che presenta massimo e minimo negativi è Gls e Min si presenta quindi una anticorrelazione. Per le altre 3 coppie si ha correlazione diretta in quanto massimo e minimo sono entrambi positivi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ragionando in valore assoluto, la coppia che risulta avere la correlazione più debole è Gls e Age nel 2020. Mentre quella più forte è Gls e Starts nel 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data_frame.columns:\n",
    "    if column not in ['Gls','Ast']:\n",
    "     correlazione('Ast',column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche in questo caso si presenta anticorrelazione con i minuti giocati, infatti anche qui il range è interamente a valori negativi. Tutte le altre hanno intervallo con massimo e minimo positivi e quindi correlazione diretta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passando al valore assoluto la coppia con la correlazione più debole è Ast e Min nel 2021. Quella più forte ad 1 è Ast e Starts nel 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) STATISTICHE DI OPPOSIZIONE\n",
    "\n",
    "In questa parte ci occupiamo di analizzare le statistiche di opposizione, ovvero quelle che il riguardano il comportamento del giocatore quando è messo a confronto con un avversario. Analizzeremo dati come dribbling, contrasti e conduzioni palla. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa parte son presenti statistiche sulla parte di campo in cui vengono registrati determinati dati. Le analizziamo separatamente in quanto vogliamo capire se c'è un impatto diverso legato all'area di campo in cui vengono registrati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = []\n",
    "\n",
    "colonne_da_eliminare = ['Player', 'Nation', 'Pos', 'Squad','Age', 'MP', 'Starts', 'Min', 'G+A', 'G-PK', 'PK',\n",
    "       'PKatt', 'CrdY', 'CrdR', 'xG', 'PrgP', 'PrgR', 'Sh', 'SoT', 'SoT%',\n",
    "       'G/Sh', 'G/SoT', 'Dist', 'FK', 'G-xG', 'Cmp', 'Att', 'Cmp%', 'xA', 'KP',\n",
    "       'PPA', 'CrsPA', 'SCA', 'GCA', 'Succ%','2CrdY', 'Off', 'Crs','Won%']\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    data_frame = pd.read_excel(file)\n",
    "    data_frame.drop(columns=colonne_da_eliminare, inplace=True) \n",
    "\n",
    "    corr_matrix = data_frame.corr()\n",
    "\n",
    "    year = year_mapping[file] \n",
    "\n",
    "    fig = px.imshow(corr_matrix, title=f\"Matrice di Correlazione - Anno {year}\", zmin = -1, zmax = 1)\n",
    "    fig.show()\n",
    "print(f'Le colonne usate per questa analisi sono {list(data_frame.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visivamente possiamo notare come in questo blocco di statistiche gli indici siano più alti rispetto a quello precedente, essendo la griglia composta da colori più caldi. Quindi ci aspettiamo che i range di correlazione siano tutti positivi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['Mid 3rd', 'Att 3rd', 'Mid 3rd.1', 'Att 3rd.1']:\n",
    "    correlazione('Gls',column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le prime due coppie sono relative ai contrasti, nella parte centrale di campo e quella offensiva. La seconda invece tratta i dribbling, anche qui divisi in parte centrale e offensiva. Per entrambe le categorie notiamo che gli intervalli degli indici sono più elevati per la parte offensiva. Quindi possiamo concludere che la parte di campo in cui vengono fatti dribbling e contrasti ha effettivamente un impatto sui Gol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['Mid 3rd', 'Att 3rd', 'Mid 3rd.1', 'Att 3rd.1']:\n",
    "    correlazione('Ast',column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo che i risultati sono simili a prima quindi il discorso è il medesimo che per i gol. Realizzare dribbling e contrasti nella parte offensiva di campo ha un impatto maggiore sugli assist piuttosto che farli a centrocampo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data_frame.columns:\n",
    "    if column not in ['Gls','Ast','Mid 3rd', 'Att 3rd', 'Mid 3rd.1', 'Att 3rd.1']:\n",
    "     correlazione('Gls',column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo che tutti i minimi sono positivi quindi siamo in presenza solamente di correlazioni dirette.\n",
    "La coppia con corelazione più debole è Gls e TklW nel 2020 . Quella più forte è Gls e Touches nel 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data_frame.columns:\n",
    "    if column not in ['Gls','Ast','Mid 3rd', 'Att 3rd', 'Mid 3rd.1', 'Att 3rd.1']:\n",
    "     correlazione('Ast',column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche qui siamo solamente in presenza di correlazioni dirette. Rispetto ai gol si hanno correlazioni più forti, come in Carries che ha registrato la correlazione più forte con Ast nel 2021, ma anche alcune più deboli come quella di Won che ha registrato l'indice di correlazione con Ast più basso nel 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) STATISTICHE DI GIOCO\n",
    "\n",
    "In questa parte andiamo ad analizzare le statistiche di creazione offensiva, quelle relative ai passaggi ai tiri e alla creazione di chance da gol o di tiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = []\n",
    "years = []\n",
    "\n",
    "colonne_da_eliminare = ['Player', 'Nation', 'Pos', 'Squad','Age', 'MP', 'Starts', 'Min', 'G+A', 'G-PK', 'PK',\n",
    "       'PKatt', 'CrdY', 'CrdR', 'SoT%', 'xG', 'xA',\n",
    "       'G/Sh', 'G/SoT', 'FK', 'G-xG','Cmp%','Tkl', 'TklW', 'Mid 3rd', 'Att 3rd',\n",
    "       'Touches', 'Mid 3rd.1', 'Att 3rd.1', 'Att.1', 'Succ', 'Succ%',\n",
    "       'Carries', 'TotDist', '2CrdY', 'Fld', 'Won', 'Lost',\n",
    "       'Won%']\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    data_frame = pd.read_excel(file)\n",
    "    data_frame.drop(columns=colonne_da_eliminare, inplace=True) \n",
    "\n",
    "    corr_matrix = data_frame.corr()\n",
    "\n",
    "    year = year_mapping[file] \n",
    "    years.append(year)\n",
    "\n",
    "    fig = px.imshow(corr_matrix, title=f\"Matrice di Correlazione - Anno {year}\", zmin = -1, zmax = 1)\n",
    "    fig.show()\n",
    "    \n",
    "print(f'Le colonne usate per questa analisi sono {list(data_frame.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In queste matrici vediamo colori molto caldi, quindi ci aspettiamo solo correlazioni dirette. Ad eccezione per una colonna con correlazione molto debole vicinissima allo zero sia per Gol che per Assist relativa a Dist, ovvero la distanza media di tiro. Risultato prevedibile. Analizziamola a parte per dimostrare ciò che abbiamo appena detto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['Gls','Ast']:\n",
    "    correlazione('Dist',column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fra Dist e Gol l'intervallo degli indici di correlazione è negativo siamo in presenza di anticorrelazione molto debole.\n",
    "Con gli Ast l'intervallo comprende valori negativi e positivi tutti vicini allo zero correlazione quindi, anche in questo caso, molto debole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data_frame.columns:\n",
    "    if column not in ['Gls','Ast','Dist']:\n",
    "     correlazione('Gls',column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come anticipato, siccome tutti i minimi sono positivi, siamo in presenza di correlazioni dirette più o meno forti. La più forte è Gls e SoT nel 2021, il range è interamente molto vicino all'uno quindi siamo in presenza di una correlazione molto forte. Al contrario la correlazione è con CrsPA registrato nel 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data_frame.columns:\n",
    "    if column not in ['Gls','Ast','Dist']:\n",
    "     correlazione('Ast',column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siamo in presenza di sole correlazioni dirette. Qua per gli assist la correlazione più forte è con GCA registrata nel 2021. Mentre la più debole è con Off registrato nel 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) GOL E ASSIST ATTESI\n",
    "\n",
    "In questa parte finale di analisi ci concentriamo sul concetto specifico di Gol ed Assist attesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I concetti di gol attesi (xG) e assist attesi (xA) sono metriche avanzate utilizzate nel calcio per misurare la qualità delle azioni da gol e degli assist, tenendo conto di fattori che influenzano la probabilità che si verifichi un gol o un assist. Il valore è compreso tra 0 e 1, dove un valore di 1 indica un evento che ha quasi certezza di verificarsi. mentre 0.1 rappresenta un tiro (ad esempio) molto difficile con poca probabilità di realizzazione.\n",
    "Nello specifico, xG prende in considerazione aspetti come:\n",
    "- Posizione del tiro: più vicino alla porta, più alta è la probabilità di segnare.\n",
    "- Angolo di tiro: tiri da angoli difficili (ad esempio, tiri da fuori area o angoli stretti) hanno una probabilità inferiore di andare in gol.\n",
    "- Posizione del portiere: se il portiere è fuori posizione o se c'è un errore difensivo, la probabilità di segnare aumenta.\n",
    "\n",
    "Come per l'xG, anche l'xA si basa su vari fattori che influenzano la probabilità di trasformare un passaggio in un gol, come:\n",
    "- Tipo di passaggio: passaggi facili da ricevere e controllare (come palloni rasoterra diretti) hanno una probabilità maggiore di diventare assist.\n",
    "- Distanza dal gol: passaggi effettuati vicino alla porta o da posizioni centrali hanno un xA più alto.\n",
    "- Posizione del ricevente: se il destinatario del passaggio è in una buona posizione per segnare, l'assist atteso sarà più alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonne_da_eliminare = ['Player', 'Nation', 'Pos', 'Squad','Age', 'MP', 'Starts', 'Min', 'G+A', 'G-PK', 'PK',\n",
    "       'PKatt', 'CrdY', 'CrdR', 'SoT%',\n",
    "       'G/Sh', 'G/SoT', 'FK', 'G-xG','Cmp%','Tkl', 'TklW', 'Mid 3rd', 'Att 3rd',\n",
    "       'Touches', 'Mid 3rd.1', 'Att 3rd.1', 'Att.1', 'Succ', 'Succ%',\n",
    "       'Carries', 'TotDist', '2CrdY', 'Fld','Won', 'Lost',\n",
    "       'Won%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat1 = 'Gls'\n",
    "stat2 = 'xG'\n",
    "correlazione(stat1,stat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come potevamo immaginarci dalla spiegazione precedente il range è estremamente vicino ad 1, quindi la correlazione è molto forte fra queste due statistiche. Il risultato è molto comprensibile in quanto dietro a questi dati ci sono studi molto profondi e complessi realizzati anche con l'aiuto di intelligenze artificiali e database pienissimi di dati di miliardi di giocatori presi in diverse annate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat1 = 'Ast'\n",
    "stat2 = 'xA'\n",
    "correlazione(stat1,stat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La correlazione anche in questo caso è forte. Lo è meno di quanto lo sono gli xG con i Gol in quanto per gli assist c'è la variabile relativa al compagno che può non riuscire a concretizzare un ottimo passaggio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSIONE\n",
    "\n",
    "La ricerca conferma la nostra tesi. Esistono statistiche che presentano correlazioni forti con Gol ed Assist. Inoltre per ogni coppia di statistiche la differenza fra il minimo ed il massimo valore che assume l'indice mostra una costanza nella correlazione delle statistiche nel corso delle stagioni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RETI NEURALI\n",
    "\n",
    "Grazie al paragrafo precedente siamo stati in grado di determinare le correlazioni delle varie statistiche con gol e assist.\n",
    "\n",
    "L'obiettivo di questa sezione è quello di usare i risultati trovati in precedenza per stimare il numero di Gol dei giocatori. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nelle prossime celle andremo ad impostare la rete neurale, importando i file ed addestrandola.\n",
    "\n",
    "Le \"incognite\" del nostro lavoro, che vanno ad determinare il risultato, sono il numero di statistiche utilizzate nella rete neurale e quello di epoche di addestramento. Lavoreremo, quindi, con due cicli for per trovare la miglior combinazione di epoche e colonne che restituisca l'errore medio minore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordiniamo le statistiche in base all'indice di correlazione con i Gol, così facendo andiamo ad inserire, per ogni iterazione del ciclo for, le statistiche in ordine di correlazione decrescente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = \"attaccanti_19.xlsx\"\n",
    "f2 = \"attaccanti_20.xlsx\"\n",
    "f3 = \"attaccanti_21.xlsx\"\n",
    "f4 = \"attaccanti_22.xlsx\"\n",
    "f5 = \"attaccanti_23.xlsx\"\n",
    "\n",
    "colonne_da_eliminare = ['Player', 'Nation', 'Pos', 'Squad','Ast','G+A', 'G-PK', 'PK','PKatt', 'CrdY', 'CrdR', 'SoT%','G/Sh',\n",
    "'G/SoT', 'FK', 'G-xG', 'Cmp%', 'Succ%','2CrdY', 'Won%']\n",
    "\n",
    "correlazioni_annuali('Gls')  # scopriamo l'ordine di correlazione per l'anno che ci interessa\n",
    "colonne_ordinate = [\"Gls\", \"xG\", \"SoT\", \"Sh\", \"GCA\", \"Starts\", \"PrgR\", \"Att 3rd.1\", \"SCA\", \"Touches\", \"Mid 3rd.1\", \"Carries\", \"KP\", \"Att\",\n",
    "                     \"MP\", \"Cmp\", \"Fld\", \"xA\", \"PrgP\", \"Off\", \"TotDist\", \"Att.1\", \"PPA\", \"Att 3rd\", \"Succ\", \"Lost\", \"Won\", \n",
    "                     \"Tkl\", \"TklW\", \"Mid 3rd\", \"Crs\", \"CrsPA\", \"Age\", \"Dist\", \"Min\"]\n",
    "# Unisco i file Excel\n",
    "df1 = pd.read_excel(f1)\n",
    "df2 = pd.read_excel(f2).iloc[1:].reset_index(drop=True)\n",
    "df3 = pd.read_excel(f3).iloc[1:].reset_index(drop=True)\n",
    "df4 = pd.read_excel(f4).iloc[1:].reset_index(drop=True)\n",
    "df_unito = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "df_unito = df_unito[colonne_ordinate]\n",
    "\n",
    "df5 = pd.read_excel(f5)\n",
    "df5 = df5.drop(columns=colonne_da_eliminare, errors='ignore')\n",
    "df5 = df5[colonne_ordinate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si fa notare che verranno prese in considerazione solamente le prime 25 statistiche (in ordine di correlazione) poichè notiamo che è il numero di colonne per cui l'errore inizia ad aumentare e non oscillare come avviene per gli intervalli precedenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-elaborazione dei dati\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Variabili per risultati complessivi\n",
    "errori_predizione = []\n",
    "num_colonne_usate = []\n",
    "minimi_errori_epoch = []  # Lista per tenere traccia dei minimi RMSE per epoche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for num_col in range(2, 25):  \n",
    "    print(f\"Training usando le prime {num_col} colonne.\")\n",
    "    \n",
    "    X = df_unito.iloc[:, 1:num_col]  # Input\n",
    "    y = df_unito.iloc[:, :1]         # Output\n",
    "    \n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, y_train = X_scaled, y\n",
    "    \n",
    "    # Variabili per memorizzare il minimo errore e il numero di epoche\n",
    "    best_rmse_prediction = float('inf')\n",
    "    best_epochs = 0\n",
    "    \n",
    "    for epochs in range(100, 1201, 100):\n",
    "    \n",
    "        model = tf.keras.Sequential([tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "            tf.keras.layers.Dense(64, activation='relu'), tf.keras.layers.Dense(y_train.shape[1])])\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    \n",
    "        X_new = df5[X.columns]\n",
    "        X_new_scaled = scaler.transform(X_new)\n",
    "        \n",
    "        y_pred = model.predict(X_new_scaled, verbose=0)\n",
    "        \n",
    "        y_pred = np.clip(y_pred, 0, None)\n",
    "        \n",
    "        y_actual = df5['Gls'].values  \n",
    "        mse_prediction = mean_squared_error(y_actual, y_pred)\n",
    "        rmse_prediction = sqrt(mse_prediction) \n",
    "        \n",
    "        # Cerco il minimo RMSE di predizione\n",
    "        if rmse_prediction < best_rmse_prediction:\n",
    "            best_rmse_prediction = rmse_prediction\n",
    "            best_epochs = epochs \n",
    "        \n",
    "    # Aggiungi i migliori risultati trovati per questa configurazione\n",
    "    errori_predizione.append(best_rmse_prediction)\n",
    "    num_colonne_usate.append(num_col)\n",
    "    minimi_errori_epoch.append((best_rmse_prediction, best_epochs))\n",
    "    \n",
    "    # Stampa il miglior risultato per colonne\n",
    "    print(f\"Con {num_col} colonne:\")\n",
    "    print(f\"Minimo RMSE Predizione: {best_rmse_prediction} (Epochs: {best_epochs})\")\n",
    "\n",
    "    # Stampa i migliori risultati per ogni configurazione\n",
    "    for i, (rmse, epochs) in enumerate(minimi_errori_epoch):\n",
    "     print(f\"Per {num_colonne_usate[i]} colonne, il miglior RMSE di predizione è {rmse} con {epochs} epoche.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il for è stato eseguito su un altro computer per via dell'elevata durata del ciclo, basti pensare il numero di epoche totali corrispondente a 195000. Vengono riportati i risultati ottenuti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per 2 colonne, il miglior RMSE di predizione è 1.907446850944147 con 100 epoche.\n",
    "Per 3 colonne, il miglior RMSE di predizione è 1.8851412553280629 con 700 epoche.\n",
    "Per 4 colonne, il miglior RMSE di predizione è 1.941661028482543 con 200 epoche.\n",
    "Per 5 colonne, il miglior RMSE di predizione è 2.084774711957049 con 100 epoche.\n",
    "Per 6 colonne, il miglior RMSE di predizione è 2.0822575432714294 con 100 epoche.\n",
    "Per 7 colonne, il miglior RMSE di predizione è 1.9618783343361386 con 100 epoche.\n",
    "Per 8 colonne, il miglior RMSE di predizione è 2.022257559384076 con 100 epoche.\n",
    "Per 9 colonne, il miglior RMSE di predizione è 2.048596509083856 con 100 epoche.\n",
    "Per 10 colonne, il miglior RMSE di predizione è 2.001122898359071 con 100 epoche.\n",
    "Per 11 colonne, il miglior RMSE di predizione è 1.9927146743435766 con 100 epoche.\n",
    "Per 12 colonne, il miglior RMSE di predizione è 1.9331462995970639 con 100 epoche.\n",
    "Per 13 colonne, il miglior RMSE di predizione è 1.9759040473452913 con 100 epoche.\n",
    "Per 14 colonne, il miglior RMSE di predizione è 1.9982565406445278 con 100 epoche.\n",
    "Per 15 colonne, il miglior RMSE di predizione è 1.9369245286742989 con 100 epoche.\n",
    "Per 16 colonne, il miglior RMSE di predizione è 1.939918307149599 con 100 epoche.\n",
    "Per 17 colonne, il miglior RMSE di predizione è 2.0128151752158936 con 100 epoche.\n",
    "Per 18 colonne, il miglior RMSE di predizione è 2.0199483868915977 con 100 epoche.\n",
    "Per 19 colonne, il miglior RMSE di predizione è 2.087056068104932 con 100 epoche.\n",
    "Per 20 colonne, il miglior RMSE di predizione è 2.0493591286211474 con 100 epoche.\n",
    "Per 21 colonne, il miglior RMSE di predizione è 2.0654617693189468 con 100 epoche.\n",
    "Per 22 colonne, il miglior RMSE di predizione è 1.9711563695446321 con 300 epoche.\n",
    "Per 23 colonne, il miglior RMSE di predizione è 2.083283808534682 con 100 epoche.\n",
    "Per 24 colonne, il miglior RMSE di predizione è 2.0020954979667303 con 100 epoche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo il grafico inserendo i dati manualmente per non far girare il codice che impiegherebbe diverse ore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_colonne = list(range(2, 25))\n",
    "rmse_values = [\n",
    "    1.907446850944147, 1.8851412553280629, 1.941661028482543, 2.084774711957049, 2.0822575432714294, 1.9618783343361386, 2.022257559384076, 2.048596509083856, \n",
    "    2.001122898359071, 1.9927146743435766, 1.9331462995970639, 1.9759040473452913, 1.9982565406445278, 1.9369245286742989, 1.939918307149599, 2.0128151752158936, \n",
    "    2.0199483868915977, 2.087056068104932, 2.0493591286211474, 2.0654617693189468, 1.9711563695446321, 2.083283808534682, 2.0020954979667303]\n",
    "\n",
    "epochs_values = [100, 700, 200, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 300, 100, 100]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax1.set_xlabel('Numero di colonne')\n",
    "ax1.set_ylabel('Errore (RMSE)')\n",
    "ax1.plot(num_colonne, rmse_values, marker='o', color='b', label='Errore (RMSE)')\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Epoche ottimali')\n",
    "ax2.plot(num_colonne, epochs_values, marker='s', color='red', label='Epoche ottimali')\n",
    "ax2.tick_params(axis='y')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.title('Errore e epoche ottimali al variare del numero di colonne')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La migliore coppia di colonne ed epoche è (3;700). Per trovare un risultato più preciso usiamo le prime 3 colonne e lavoriamo con un range più piccolo di epoche ad intervalli minori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prime 3 colonne come input\n",
    "num_col = 3\n",
    "print(f\"Training usando le prime {num_col} colonne.\")\n",
    "\n",
    "X = df_unito.iloc[:, 1:num_col]  \n",
    "y = df_unito.iloc[:, :1]        \n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, y_train = X_scaled, y\n",
    "\n",
    "best_rmse_prediction = float('inf')\n",
    "best_epochs = 0\n",
    "\n",
    "for epochs in range(640, 801, 20):\n",
    "    model = tf.keras.Sequential([tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),tf.keras.layers.Dense(y_train.shape[1])])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    X_new = df5[X.columns]\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "    \n",
    "    y_pred = model.predict(X_new_scaled, verbose=0)\n",
    "    \n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "    \n",
    "    y_actual = df5['Gls'].values\n",
    "    mse_prediction = mean_squared_error(y_actual, y_pred)\n",
    "    rmse_prediction = sqrt(mse_prediction)  \n",
    "    \n",
    "    if rmse_prediction < best_rmse_prediction:\n",
    "        best_rmse_prediction = rmse_prediction\n",
    "        best_epochs = epochs \n",
    "\n",
    "print(f\"Con {num_col} colonne:\")\n",
    "print(f\"Minimo RMSE Predizione: {best_rmse_prediction} (Epochs: {best_epochs})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trovato il miglior numero di epoche per le colonne desiderate, plottiamo un grafico nel quale rappresentiamo visiamente le predizioni della nostra rete neurale, in confronto alla bisettrice che rappresenta il valore esatto dei Gol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual=np.array([y_actual])\n",
    "y_pred=np.array([y_pred])\n",
    "y_pred = y_pred.squeeze()\n",
    "y_actual = y_actual.squeeze()\n",
    "\n",
    "fuori_dalla_linea = (y_actual < y_pred - best_rmse_prediction) | (y_actual > y_pred + best_rmse_prediction)\n",
    "\n",
    "y_actual_fuori = y_actual[fuori_dalla_linea]\n",
    "y_pred_fuori = y_pred[fuori_dalla_linea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_actual, y_pred, alpha=0.7, edgecolors='k', label='Previsioni')\n",
    "plt.plot([0, max(y_actual)], [0, max(y_actual)], color = 'k', label='Linea Perfetta')\n",
    "plt.xlabel(\"Goal Reali\")\n",
    "plt.ylabel(\"Goal Previsti\")\n",
    "plt.title(\"Confronto tra Goal Reali e Goal Previsti\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo con soddisfazione che la nostra rete neurale restituisce valori coerenti con quelli con il grafico desiderato y = x. Andiamo ora a valutare l'efficienza, ovvero il numero di giocatori la cui barra di errore interseca la retta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.errorbar(y_actual, y_pred, fmt='o', ecolor='green', color='green', alpha = 0.5, label='Previsioni accettabili')\n",
    "\n",
    "plt.errorbar(y_actual_fuori, y_pred_fuori, fmt='o', color='red', alpha = 0.5, label='Previsioni non accettabili')\n",
    "\n",
    "plt.plot([0, max(y_actual)], [0, max(y_actual)], color='black', label='Linea Perfetta')\n",
    "\n",
    "plt.plot([0, max(y_actual)], [rmse_prediction, max(y_actual) + rmse_prediction], color='k', linestyle='--', label='Linea +RMSE')\n",
    "plt.plot([0, max(y_actual)], [-rmse_prediction, max(y_actual) - rmse_prediction], color='k', linestyle='--', label='Linea -RMSE')\n",
    "\n",
    "plt.xlabel(\"Goal Reali\")\n",
    "plt.ylabel(\"Goal Previsti\")\n",
    "plt.title(\"Confronto tra Goal Reali e Goal Previsti con Linee RMSE\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "num_fuori_dalla_linea = np.sum(fuori_dalla_linea)\n",
    "\n",
    "print(f\"Numero di giocatori fuori dal range: {num_fuori_dalla_linea}\")\n",
    "print(f\"Numero di giocatori nel range: {194 - num_fuori_dalla_linea}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La maggior parte dei punti verdi si concentra nella parte bassa del grafico, con valori reali e previsti intorno a 0-10.\n",
    "Gli outlier (punti rossi) appaiono più frequenti in corrispondenza di valori elevati dei goal reali o previsti (ad esempio, sopra 15-20), suggerendo che il modello può avere difficoltà con predizioni per valori estremi.\n",
    "Il modello sembra funzionare meglio per i valori bassi di goal reali e previsti, ma perde precisione man mano che i valori aumentano.\n",
    "Una possibile spiegazione è che il dataset contenga meno osservazioni con goal elevati o che il modello non riesca a generalizzare per queste situazioni."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
