{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3873b251",
   "metadata": {},
   "source": [
    "Questa sezione di codice si occupa delle reti neurali. Grazie all'analisi di correlazione abbiamo capito quali statistiche sono correlate con i dati di Gol ed Assist. Daremo quindi in input alla rete neurale quelle statistiche e chiederemo in output, appunto, Gol ed Assist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0455a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo le librerie necessarie\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "105187ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nelle prossime celle andremo ad impostare la rete neurale, importando i file ed addestrandola con i file di input. \n",
    "# Andiamo a fare prima i gol e nella cella seguente la rete per gli assist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3299c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = \"attaccanti_19.xlsx\"\n",
    "f2 = \"attaccanti_20.xlsx\"\n",
    "f3 = \"attaccanti_21.xlsx\"\n",
    "f4 = \"attaccanti_22.xlsx\"\n",
    "f5 = \"attaccanti_23.xlsx\"\n",
    "\n",
    "# Elimino le colonne che abbiamo scoperto essere non utili per la nostra analisi\n",
    "\n",
    "colonne_da_eliminare = ['Player', 'Nation', 'Pos', 'Squad', 'Age', 'MP', 'Starts', 'Min', 'G+A', 'G-PK', 'PK', 'PKatt', \n",
    "                        'CrdY', 'CrdR', 'SoT%', 'G/Sh', 'G/SoT', 'Dist', 'FK', 'G-xG','Cmp', 'Att','CrsPA', 'Cmp%', 'Tkl',\n",
    "                        'TklW', 'Mid 3rd', 'Att 3rd', 'Mid 3rd.1','Succ%', 'TotDist', '2CrdY', 'Fld', 'Off','Crs', 'Won', 'Lost', 'Won%']\n",
    "\n",
    "# Unisco i file Excel\n",
    "df1 = pd.read_excel(f1)\n",
    "df2 = pd.read_excel(f2).iloc[1:].reset_index(drop=True)\n",
    "df3 = pd.read_excel(f3).iloc[1:].reset_index(drop=True)\n",
    "df4 = pd.read_excel(f4).iloc[1:].reset_index(drop=True)\n",
    "df_unito = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "\n",
    "# Rimuovo le colonne\n",
    "df_unito = df_unito.drop(columns=colonne_da_eliminare, errors='ignore')\n",
    "\n",
    "df5 = pd.read_excel(f5).iloc[1:].reset_index(drop=True)\n",
    "df5 = df5.drop(columns=colonne_da_eliminare, errors='ignore')\n",
    "\n",
    "# Separare le colonne in input e output\n",
    "X = df_unito.iloc[:, 2:]  # Tutte le colonne eccetto le prime due\n",
    "y = df_unito.iloc[:, :2]  # Le prime due colonne\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Divisione in set di addestramento e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Costruzione della rete neurale\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "                             tf.keras.layers.Dense(64, activation='relu'),\n",
    "                             tf.keras.layers.Dense(y_train.shape[1])])\n",
    "\n",
    "# Compilazione\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Addestramento\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Carica il nuovo file e pre-processa i dati\n",
    "df_new = df5  \n",
    "\n",
    "# Verifica che le colonne siano allineate con il DataFrame di addestramento\n",
    "X_new = df_new[X.columns]\n",
    "\n",
    "# Pre-elabora i dati nuovi\n",
    "X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "# Usa il modello per fare previsioni\n",
    "y_pred = model.predict(X_new_scaled)\n",
    "\n",
    "# Imposto pari a zero i valori negativi in quanto è impossibile realizzare un numero negativo di gol\n",
    " \n",
    "y_pred = np.clip(y_pred, 0, None)  # Sostituisci i valori negativi con 0\n",
    "\n",
    "# Visualizza le previsioni\n",
    "df_new['Pred_Gls'] = y_pred[:, 0]  # Previsioni per la prima colonna (Gls)\n",
    "df_new['Pred_Ast'] = y_pred[:, 1]  # Previsioni per la seconda colonna (Ast)\n",
    "\n",
    "print(df_new[['Gls', 'Ast', 'Pred_Gls', 'Pred_Ast']])\n",
    "\n",
    "# Calcola separatamente la somma delle previsioni per Gls e Ast\n",
    "somma_goal_attesi = df_new['Pred_Gls'].sum()\n",
    "somma_assist_attesi = df_new['Pred_Ast'].sum()\n",
    "\n",
    "# Calcola separatamente la somma effettiva dei goal e assist nei dati originali\n",
    "somma_goal = df_new['Gls'].sum()\n",
    "somma_assist = df_new['Ast'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4677d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risultati dei gol\n",
    "print(f\"La somma dei goal effettivi è {somma_goal}\")\n",
    "print(f\"La somma dei goal ottenuti dalla rete neurale è {somma_goal_attesi}\")\n",
    "\n",
    "# Risultati degli assist\n",
    "\n",
    "print(f\"La somma degli assist effettivi è {somma_assist}\")\n",
    "print(f\"La somma degli assist ottenuti dalla rete neurale è {somma_assist_attesi}\")\n",
    "\n",
    "# Errore\n",
    "\n",
    "diff_gol = abs(somma_goal - somma_goal_attesi)\n",
    "diff_ast = abs(somma_assist - somma_assist_attesi)\n",
    "\n",
    "# Trovo l'errore medio dividendo per il numero di giocatori \n",
    "\n",
    "avg_err_gol = diff_gol/194  \n",
    "avg_err_ast = diff_ast/194\n",
    "\n",
    "print(f\"La differenza fra la somma effettiva e quella della rete neurale è di {diff_gol} Gol\")\n",
    "print(f\"La differenza fra la somma effettiva e quella della rete neurale è di {diff_ast} Assist\")\n",
    "print(f\"L'errore medio per i gol è {avg_err_gol} per giocatore\")\n",
    "print(f\"L'errore medio per gli assist è {avg_err_ast} per giocatore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4658d6",
   "metadata": {},
   "source": [
    "Aumentando il numero delle epoche ovviamente la differenza fra la previsione della rete neurale e la somma effettiva delle statistiche richieste si assottiglia notevolmente. Il processo richiede più tempo ma restituisce risultati più precisi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
